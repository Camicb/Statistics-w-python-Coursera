{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NHANES Hypothesis Testing Walkthrough.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOwlqjwH2kMq0NwmI+Lfa1p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Camicb/Statistics-w-python-Coursera/blob/master/NHANES_Hypothesis_Testing_Walkthrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzAqUYYbDR_1"
      },
      "source": [
        "# Hypothesis Testing\n",
        "\n",
        "In this notebook we demonstrate formal hypothesis testing using the NHANES data.\n",
        "\n",
        "It is important to note that the NHANES data are a \"complex survey\".  The data are not an independent and representative sample from the target population.  Proper analysis of complex survey data should make use of additional information about how the data were collected.  Since complex survey analysis is a somewhat specialized topic, we ignore this aspect of the data here, and analyze the NHANES data as if it were an independent and identically distributed sample from a population."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qt0u8asDW80"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF2LxLeGDcsn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg') # workaround, there may be a better way\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import scipy.stats.distributions as dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10pBkgtsFFMj"
      },
      "source": [
        "Below we read the data, and convert some of the integer codes to text values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFT7Ve-xFGNG"
      },
      "source": [
        "url = \"nhanes_2015_2016.csv\"\n",
        "da = pd.read_csv(url)\n",
        "\n",
        "da[\"SMQ020x\"] = da.SMQ020.replace({1: \"Yes\", 2: \"No\", 7: np.nan, 9: np.nan})\n",
        "da[\"SMQ020x\"].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkPU9xMzFRo2"
      },
      "source": [
        "da[\"RIAGENDRx\"] = da.RIAGENDR.replace({1: \"Male\", 2: \"Female\"})\n",
        "\n",
        "da[\"RIAGENDRx\"].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWy6m10yFtna"
      },
      "source": [
        "### Hypothesis Tests for One Proportion\n",
        "\n",
        "The most basic hypothesis test may be the one-sample test for a proportion.  This test is used if we have specified a particular value as the null value for the proportion, and we wish to assess if the data are compatible with the true parameter value being equal to this specified value.  One-sample tests are not used very often in practice, because it is not very common that we have a specific fixed value to use for comparison. For illustration, imagine that the rate of lifetime smoking in another country was known to be 40%, and we wished to assess whether the rate of lifetime smoking in the US were different from 40%.  In the following notebook cell, we carry out the (two-sided) one-sample test that the population proportion of smokers is 0.4, and obtain a p-value of 0.43.  This indicates that the NHANES data are compatible with the proportion of (ever) smokers in the US being 40%. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijLcauZ-FwK7"
      },
      "source": [
        "x = da.SMQ020x.dropna() == \"Yes\"\n",
        "p = x.mean()\n",
        "se = np.sqrt(.4 * (1 - .4)/ len(x))\n",
        "test_stat = (p - 0.4) / se\n",
        "pvalue = 2 * dist.norm.cdf(-np.abs(test_stat))\n",
        "print('mean:', p, 'se:', se, 'test stat:',test_stat, 'p-value:',pvalue)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgrIIe9tGqko"
      },
      "source": [
        "The following cell carries out the same test as performed above using the Statsmodels library.  The results in the first (default) case below are slightly different from the results obtained above because Statsmodels by default uses the sample proportion instead of the null proportion when computing the standard error.  This distinction is rarely consequential, but we can specify that the null proportion should be used to calculate the standard error, and the results agree exactly with what we calculated above.  The first two lines below carry out tests using the normal approximation to the sampling distribution of the test statistic, and the third line below carries uses the exact binomial sampling distribution.  We can see here that the p-values are nearly identical in all three cases. This is expected when the sample size is large, and the proportion is not close to either 0 or 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQbZNeOiGtXi"
      },
      "source": [
        "sm.stats.proportions_ztest(x.sum(), len(x), 0.4) #Normal approximation w/ estimated proportion in SE\n",
        "#print test stat, p-value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gntt8eoRGwEG"
      },
      "source": [
        "sm.stats.binom_test(x.sum(), len(x), 0.4) #Exact binomial p-value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTzCmv-iHSBz"
      },
      "source": [
        "### Hypothesis Tests for Two Proportions\n",
        "\n",
        "Comparative tests tend to be used much more frequently than tests comparing one population to a fixed value.  A two-sample test of proportions is used to assess whether the proportion of individuals with some trait differs between two sub-populations.  For example, we can compare the smoking rates between females and males. Since smoking rates vary strongly with age, we do this in the subpopulation of people between 20 and 25 years of age.  In the cell below, we carry out this test without using any libraries, implementing all the test procedures covered elsewhere in the course using Python code.  We find that the smoking rate for men is around 10 percentage points greater than the smoking rate for females, and this difference is statistically significant (the p-value is around 0.01)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7dsJbIzHVzV"
      },
      "source": [
        "dx = da[[\"SMQ020x\", \"RIDAGEYR\", \"RIAGENDRx\"]].dropna()\n",
        "dx=dx.loc[(dx.RIDAGEYR>=20) & (dx.RIDAGEYR<=25), :]\n",
        "dx.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUZ4nQ9MHb4N"
      },
      "source": [
        "p = dx.groupby(\"RIAGENDRx\")[\"SMQ020x\"].agg([lambda z: np.mean(z == \"Yes\"), \"size\"])\n",
        "p.columns = [\"Smoke\", \"N\"]\n",
        "print(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yfyA-O6Hj08"
      },
      "source": [
        "Essentially the same test as above can be conducted by converting the \"Yes\"/\"No\" responses to numbers (Yes=1, No=0) and conducting a two-sample t-test, as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9bNEDO1HgfF"
      },
      "source": [
        "p_comb = (dx.SMQ020x == \"Yes\").mean()\n",
        "va = p_comb * (1 - p_comb)\n",
        "se = np.sqrt(va * (1 / p.N.Female + 1 / p.N.Male))\n",
        "(p_comb, va, se)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUzlP8YbHtuK"
      },
      "source": [
        "test_stat = (p.Smoke.Female - p.Smoke.Male) / se\n",
        "p_value = 2 * dist.norm.cdf(-np.abs(test_stat))\n",
        "(test_stat, p_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNwzCYUEH1uX"
      },
      "source": [
        "#ahora con bibliotecas\n",
        "dx_females = dx.loc[dx.RIAGENDRx == \"Female\", \"SMQ020x\"].replace({\"Yes\": 1, \"No\": 0})\n",
        "dx_males = dx.loc[dx.RIAGENDRx == \"Male\", \"SMQ020x\"].replace({\"Yes\": 1, \"No\": 0})\n",
        "sm.stats.ttest_ind(dx_females, dx_males) # print test statistic, p-value, degree of freedom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_v6HhNfIgoM"
      },
      "source": [
        "### Hypothesis Tests Comparing Means\n",
        "\n",
        "Tests of means are similar in many ways to tests of proportions.  Just as with proportions, for comparing means there are one and two-sample tests, z-tests and t-tests, and one-sided and two-sided tests.  As with tests of proportions, one-sample tests of means are not very common, but we illustrate a one sample test in the cell below.  We compare systolic blood pressure to the fixed value 120 (which is the lower threshold for \"pre-hypertension\"), and find that the mean is significantly different from 120 (the point estimate of the mean is 126)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUtof3QBIhvl"
      },
      "source": [
        "dx = da[[\"BPXSY1\", \"RIDAGEYR\", \"RIAGENDRx\"]].dropna()\n",
        "dx = dx.loc[(dx.RIDAGEYR >= 40) & (dx.RIDAGEYR <= 50) & (dx.RIAGENDRx == \"Male\"), :]\n",
        "print(dx.BPXSY1.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91K1uiCiIrNf"
      },
      "source": [
        "sm.stats.ztest(dx.BPXSY1, value=120) #print test statistic, p-value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QooPc2iIxQh"
      },
      "source": [
        "In the cell below, we carry out a formal test of the null hypothesis that the mean blood pressure for women between the ages of 50 and 60 is equal to the mean blood pressure of men between the ages of 50 and 60.  The results indicate that while the mean systolic blood pressure for men is slightly greater than that for women (129 mm/Hg versus 128 mm/Hg), this difference is not statistically significant. \n",
        "\n",
        "There are a number of different variants on the two-sample t-test. Two often-encountered variants are the t-test carried out using the t-distribution, and the t-test carried out using the normal approximation to the reference distribution of the test statistic, often called a z-test.  Below we display results from both these testing approaches.  When the sample size is large, the difference between the t-test and z-test is very small.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yk0baEFIyCh"
      },
      "source": [
        "dx = da[[\"BPXSY1\", \"RIDAGEYR\", \"RIAGENDRx\"]].dropna()\n",
        "dx = dx.loc[(dx.RIDAGEYR >= 50) & (dx.RIDAGEYR <= 60), :]\n",
        "dx.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W_qg6vUI1WN"
      },
      "source": [
        "bpx_female = dx.loc[dx.RIAGENDRx==\"Female\", \"BPXSY1\"]\n",
        "bpx_male = dx.loc[dx.RIAGENDRx==\"Male\", \"BPXSY1\"]\n",
        "print(bpx_female.mean(), bpx_male.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0lFy7PzI5EG"
      },
      "source": [
        "print(sm.stats.ztest(bpx_female, bpx_male))\n",
        "print(sm.stats.ttest_ind(bpx_female, bpx_male))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVS-NoczLJOH"
      },
      "source": [
        "Another important aspect of two-sample mean testing is \"heteroscedasticity\", meaning that the variances within the two groups being compared may be different. While the goal of the test is to compare the means, the variances play an important role in calibrating the statistics (deciding how big the mean difference needs to be to be declared statisitically significant). In the NHANES data, we see that there are moderate differences between the amount of variation in BMI for females and for males, looking within 10-year age bands. In every age band, females having greater variation than males. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uias2uPCLKiW"
      },
      "source": [
        "dx = da[[\"BMXBMI\", \"RIDAGEYR\", \"RIAGENDRx\"]].dropna()\n",
        "da[\"agegrp\"] = pd.cut(da.RIDAGEYR, [18, 30, 40, 50, 60, 70, 80])\n",
        "da.groupby([\"agegrp\", \"RIAGENDRx\"])[\"BMXBMI\"].agg(np.std).unstack()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03_q9ycCLPla"
      },
      "source": [
        "The standard error of the mean difference (e.g. mean female blood pressure minus mean mal blood pressure) can be estimated in at least two different ways. In the statsmodels library, these approaches are referred to as the \"pooled\" and the \"unequal\" approach to estimating the variance. If the variances are equal (i.e. there is no heteroscedasticity), then there should be little difference between the two approaches. Even in the presence of moderate heteroscedasticity, as we have here, we can see that the results for the two differences are quite similar. Below we have a loop that considers each 10-year age band and assesses the evidence for a difference in mean BMI for women and for men. The results printed in each row of output are the test-statistic and p-value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0XshvFQLRJO"
      },
      "source": [
        "for k, v in da.groupby(\"agegrp\"):\n",
        "    bmi_female = v.loc[v.RIAGENDRx==\"Female\", \"BMXBMI\"].dropna()\n",
        "    bmi_female = sm.stats.DescrStatsW(bmi_female)\n",
        "    bmi_male = v.loc[v.RIAGENDRx==\"Male\", \"BMXBMI\"].dropna()\n",
        "    bmi_male = sm.stats.DescrStatsW(bmi_male)\n",
        "    print(k)\n",
        "    print(\"pooled: \", sm.stats.CompareMeans(bmi_female, bmi_male).ztest_ind(usevar='pooled'))\n",
        "    print(\"unequal: \", sm.stats.CompareMeans(bmi_female, bmi_male).ztest_ind(usevar='unequal'))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}